{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.dataset import MakeNIERDataset\n",
    "from src.utils import load_data, check_array, plot_pca_explained_variances, show_obj_struct\n",
    "# from dataset_maker import db_to_pkl, preprocessing, region_flatten_cwdb, load_data, check_array, plot_pca_explained_variances, show_obj_struct, MakeNIERDataset, NIERDataset\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "seed = 999\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pink/dust/NIER_v5/src/dataset/preprocessing.py:243: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  obs_df[\"WEEK_NO_CN\"].loc[obs_df[\"WEEK_NO_CN\"] >= 6] = 1\n",
      "/home/pink/dust/NIER_v5/src/dataset/preprocessing.py:245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  obs_df[\"WEEK_NO_KR\"].loc[obs_df[\"WEEK_NO_KR\"] >= 6] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All OBS Record Correct\n",
      "All FNL Record Correct\n",
      "All WRF Record Correct\n",
      "All CMAQ Record Correct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.dataset.preprocessing.MakeNIERDataset at 0x7f05b770aee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MakeNIERDataset(reset_db=False, save_processed_data=True, run_pca=True, start_date=20190101, until_date=20211231, test_date=20210101, predict_region='R4_62', remove_region=0, preprocess_root='data_folder/', root_dir='data_folder/', rmgroup_file='../NIER_v5/data_folder/height_region_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_folder/obs_r4_um.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m/home/pink/dust/NIER_v5/data_gen.ipynb Cell 3\u001B[0m in \u001B[0;36m4\n\u001B[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpink/home/pink/dust/NIER_v5/data_gen.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001B[0m data_dir \u001B[39m=\u001B[39m \u001B[39m\"\u001B[39m\u001B[39mheight_data_folder\u001B[39m\u001B[39m\"\u001B[39m\n\u001B[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bpink/home/pink/dust/NIER_v5/data_gen.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001B[0m \u001B[39m# def make_dataset(): # 데이터셋 생성코드\u001B[39;00m\n\u001B[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bpink/home/pink/dust/NIER_v5/data_gen.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001B[0m _ \u001B[39m=\u001B[39m MakeNIERDataset(reset_db\u001B[39m=\u001B[39;49m\u001B[39mFalse\u001B[39;49;00m, save_processed_data\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m, run_pca\u001B[39m=\u001B[39;49m\u001B[39mTrue\u001B[39;49;00m, start_date\u001B[39m=\u001B[39;49m\u001B[39m20190101\u001B[39;49m, until_date\u001B[39m=\u001B[39;49m\u001B[39m20211231\u001B[39;49m, test_date\u001B[39m=\u001B[39;49m\u001B[39m20210101\u001B[39;49m, predict_region\u001B[39m=\u001B[39;49m\u001B[39m'\u001B[39;49m\u001B[39mR4_62\u001B[39;49m\u001B[39m'\u001B[39;49m,root_dir\u001B[39m=\u001B[39;49m\u001B[39m'\u001B[39;49m\u001B[39mdata_folder/\u001B[39;49m\u001B[39m'\u001B[39;49m, remove_region\u001B[39m=\u001B[39;49m\u001B[39m0\u001B[39;49m, preprocess_root\u001B[39m=\u001B[39;49m\u001B[39m'\u001B[39;49m\u001B[39mdata_folder/\u001B[39;49m\u001B[39m'\u001B[39;49m, rmgroup_file\u001B[39m=\u001B[39;49m\u001B[39m'\u001B[39;49m\u001B[39m../NIER_v5/data_folder/height_region_list.csv\u001B[39;49m\u001B[39m'\u001B[39;49m)\n",
      "File \u001B[0;32m~/dust/NIER_v5/src/dataset/preprocessing.py:42\u001B[0m, in \u001B[0;36mMakeNIERDataset.__init__\u001B[0;34m(self, reset_db, start_date, until_date, test_date, seed, preprocess_root, root_dir, save_processed_data, run_pca, predict_region, remove_region, rmgroup_file)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mpredict_region \u001B[39m=\u001B[39m predict_region\n\u001B[1;32m     41\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mrm_regions \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mbuild_rm_region(rmgroup_file, remove_region, predict_region) \u001B[39m# list of region to remove\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mpreprocess()\n\u001B[1;32m     44\u001B[0m \u001B[39mif\u001B[39;00m run_pca:\n\u001B[1;32m     45\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mhandle_pca()\n",
      "File \u001B[0;32m~/dust/NIER_v5/src/dataset/preprocessing.py:70\u001B[0m, in \u001B[0;36mMakeNIERDataset.preprocess\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mpreprocess\u001B[39m(\u001B[39mself\u001B[39m):\n\u001B[1;32m     69\u001B[0m     \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39msave_processed_data:\n\u001B[0;32m---> 70\u001B[0m         obs_df, fnl_df, wrf_df, cmaq_df, cwdb_df, ewkr_df \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_select_by_date()\n\u001B[1;32m     72\u001B[0m         obs_train, obs_test, obs_scaler \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_preprocess_df(obs_df, \u001B[39m'\u001B[39m\u001B[39mobs\u001B[39m\u001B[39m'\u001B[39m, test_date\u001B[39m=\u001B[39m\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtest_date)\n\u001B[1;32m     73\u001B[0m         cw_train, cw_test, cw_scaler \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_preprocess_df(cwdb_df, \u001B[39m'\u001B[39m\u001B[39mcwdb\u001B[39m\u001B[39m'\u001B[39m, test_date\u001B[39m=\u001B[39m\u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtest_date)\n",
      "File \u001B[0;32m~/dust/NIER_v5/src/dataset/preprocessing.py:226\u001B[0m, in \u001B[0;36mMakeNIERDataset._select_by_date\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m_select_by_date\u001B[39m(\u001B[39mself\u001B[39m):\n\u001B[0;32m--> 226\u001B[0m     obs_df, fnl_df, wrf_df, cmaq_df, cwdb_df, ewkr_df \u001B[39m=\u001B[39m db_to_pkl(get_data\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mreset_db,\n\u001B[1;32m    227\u001B[0m                                                                   root_dir\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mroot_dir )\n\u001B[1;32m    229\u001B[0m     \u001B[39m############## 날짜 튜닝 시 작업해야할 부분 ######################\u001B[39;00m\n\u001B[1;32m    231\u001B[0m     obs_df \u001B[39m=\u001B[39m obs_df[(obs_df[\u001B[39m'\u001B[39m\u001B[39mRAW_DATE\u001B[39m\u001B[39m'\u001B[39m] \u001B[39m>\u001B[39m\u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mstart_date) \u001B[39m&\u001B[39m (obs_df[\u001B[39m'\u001B[39m\u001B[39mRAW_DATE\u001B[39m\u001B[39m'\u001B[39m] \u001B[39m<\u001B[39m\u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39muntil_date)]\n",
      "File \u001B[0;32m~/dust/NIER_v5/src/utils/dataset_utils.py:64\u001B[0m, in \u001B[0;36mdb_to_pkl\u001B[0;34m(get_data, root_dir)\u001B[0m\n\u001B[1;32m     61\u001B[0m     cmaq_df\u001B[39m.\u001B[39mto_pickle(os\u001B[39m.\u001B[39mpath\u001B[39m.\u001B[39mjoin(root_dir, \u001B[39m\"\u001B[39m\u001B[39mcmaq_r4_um.pkl\u001B[39m\u001B[39m\"\u001B[39m))\n\u001B[1;32m     63\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m     obs_df \u001B[39m=\u001B[39m pd\u001B[39m.\u001B[39;49mread_pickle(os\u001B[39m.\u001B[39;49mpath\u001B[39m.\u001B[39;49mjoin(root_dir, \u001B[39m\"\u001B[39;49m\u001B[39mobs_r4_um.pkl\u001B[39;49m\u001B[39m\"\u001B[39;49m))\n\u001B[1;32m     65\u001B[0m     fnl_df \u001B[39m=\u001B[39m pd\u001B[39m.\u001B[39mread_pickle(os\u001B[39m.\u001B[39mpath\u001B[39m.\u001B[39mjoin(root_dir, \u001B[39m\"\u001B[39m\u001B[39mfnl_r4.pkl\u001B[39m\u001B[39m\"\u001B[39m))\n\u001B[1;32m     66\u001B[0m     cwdb_df \u001B[39m=\u001B[39m pd\u001B[39m.\u001B[39mread_pickle(os\u001B[39m.\u001B[39mpath\u001B[39m.\u001B[39mjoin(root_dir, \u001B[39m\"\u001B[39m\u001B[39mcwdb_r4_um.pkl\u001B[39m\u001B[39m\"\u001B[39m))\n",
      "File \u001B[0;32m~/.conda/envs/dust/lib/python3.8/site-packages/pandas/io/pickle.py:190\u001B[0m, in \u001B[0;36mread_pickle\u001B[0;34m(filepath_or_buffer, compression, storage_options)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m    125\u001B[0m \u001B[39mLoad pickled pandas object (or any object) from file.\u001B[39;00m\n\u001B[1;32m    126\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    187\u001B[0m \u001B[39m4    4    9\u001B[39;00m\n\u001B[1;32m    188\u001B[0m \u001B[39m\"\"\"\u001B[39;00m\n\u001B[1;32m    189\u001B[0m excs_to_catch \u001B[39m=\u001B[39m (\u001B[39mAttributeError\u001B[39;00m, \u001B[39mImportError\u001B[39;00m, \u001B[39mModuleNotFoundError\u001B[39;00m, \u001B[39mTypeError\u001B[39;00m)\n\u001B[0;32m--> 190\u001B[0m \u001B[39mwith\u001B[39;00m get_handle(\n\u001B[1;32m    191\u001B[0m     filepath_or_buffer,\n\u001B[1;32m    192\u001B[0m     \u001B[39m\"\u001B[39;49m\u001B[39mrb\u001B[39;49m\u001B[39m\"\u001B[39;49m,\n\u001B[1;32m    193\u001B[0m     compression\u001B[39m=\u001B[39;49mcompression,\n\u001B[1;32m    194\u001B[0m     is_text\u001B[39m=\u001B[39;49m\u001B[39mFalse\u001B[39;49;00m,\n\u001B[1;32m    195\u001B[0m     storage_options\u001B[39m=\u001B[39;49mstorage_options,\n\u001B[1;32m    196\u001B[0m ) \u001B[39mas\u001B[39;00m handles:\n\u001B[1;32m    197\u001B[0m \n\u001B[1;32m    198\u001B[0m     \u001B[39m# 1) try standard library Pickle\u001B[39;00m\n\u001B[1;32m    199\u001B[0m     \u001B[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001B[39;00m\n\u001B[1;32m    200\u001B[0m     \u001B[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001B[39;00m\n\u001B[1;32m    202\u001B[0m     \u001B[39mtry\u001B[39;00m:\n\u001B[1;32m    203\u001B[0m         \u001B[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001B[39;00m\n\u001B[1;32m    204\u001B[0m         \u001B[39mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/.conda/envs/dust/lib/python3.8/site-packages/pandas/io/common.py:865\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    856\u001B[0m         handle \u001B[39m=\u001B[39m \u001B[39mopen\u001B[39m(\n\u001B[1;32m    857\u001B[0m             handle,\n\u001B[1;32m    858\u001B[0m             ioargs\u001B[39m.\u001B[39mmode,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    861\u001B[0m             newline\u001B[39m=\u001B[39m\u001B[39m\"\u001B[39m\u001B[39m\"\u001B[39m,\n\u001B[1;32m    862\u001B[0m         )\n\u001B[1;32m    863\u001B[0m     \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    864\u001B[0m         \u001B[39m# Binary mode\u001B[39;00m\n\u001B[0;32m--> 865\u001B[0m         handle \u001B[39m=\u001B[39m \u001B[39mopen\u001B[39;49m(handle, ioargs\u001B[39m.\u001B[39;49mmode)\n\u001B[1;32m    866\u001B[0m     handles\u001B[39m.\u001B[39mappend(handle)\n\u001B[1;32m    868\u001B[0m \u001B[39m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data_folder/obs_r4_um.pkl'"
     ]
    }
   ],
   "source": [
    "data_dir = \"height_data_folder\"\n",
    "\n",
    "# def make_dataset(): # 데이터셋 생성코드\n",
    "_ = MakeNIERDataset(reset_db=False, save_processed_data=True, run_pca=True, start_date=20190101, until_date=20211231, test_date=20210101, predict_region='R4_62',root_dir='data_folder/', remove_region=0, preprocess_root='data_folder/', rmgroup_file='../NIER_v5/data_folder/height_region_list.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R4_62\n",
      "R4_77.pkl aleady in data_folder\n",
      "R4_74-R4_75-R4_76-R4_77.pkl aleady in data_folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pink/.conda/envs/dust/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove region:  R4_64\n",
      "remove region:  R4_74\n",
      "remove region:  R4_75\n",
      "remove region:  R4_76\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_74\n",
      "remove region:  R4_75\n",
      "remove region:  R4_76\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_74\n",
      "remove region:  R4_75\n",
      "remove region:  R4_76\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_74\n",
      "remove region:  R4_75\n",
      "remove region:  R4_76\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_74\n",
      "remove region:  R4_75\n",
      "remove region:  R4_76\n",
      "remove region:  R4_77\n",
      "numeric - remove region:  R4_64\n",
      "numeric - remove region:  R4_74\n",
      "numeric - remove region:  R4_75\n",
      "numeric - remove region:  R4_76\n",
      "numeric - remove region:  R4_77\n",
      "R4_64\n",
      "R4_77.pkl aleady in data_folder\n",
      "R4_69-R4_72-R4_77.pkl aleady in data_folder\n",
      "R4_69-R4_72-R4_73-R4_77.pkl aleady in data_folder\n",
      "R4_67\n",
      "R4_77.pkl aleady in data_folder\n",
      "R4_74-R4_75-R4_76-R4_77.pkl aleady in data_folder\n",
      "R4_64-R4_74-R4_75-R4_76-R4_77.pkl aleady in data_folder\n",
      "R4_69\n",
      "R4_77.pkl aleady in data_folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pink/.conda/envs/dust/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove region:  R4_64\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_77\n",
      "numeric - remove region:  R4_64\n",
      "numeric - remove region:  R4_77\n",
      "R4_64-R4_74-R4_75-R4_76-R4_77.pkl aleady in data_folder\n",
      "R4_71\n",
      "R4_77.pkl aleady in data_folder\n",
      "R4_73-R4_77.pkl aleady in data_folder\n",
      "R4_69-R4_72-R4_73-R4_77.pkl aleady in data_folder\n",
      "R4_73\n",
      "R4_77.pkl aleady in data_folder\n",
      "R4_64-R4_77.pkl aleady in data_folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pink/.conda/envs/dust/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove region:  R4_64\n",
      "remove region:  R4_70\n",
      "remove region:  R4_71\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_70\n",
      "remove region:  R4_71\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_70\n",
      "remove region:  R4_71\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_70\n",
      "remove region:  R4_71\n",
      "remove region:  R4_77\n",
      "remove region:  R4_64\n",
      "remove region:  R4_70\n",
      "remove region:  R4_71\n",
      "remove region:  R4_77\n",
      "numeric - remove region:  R4_64\n",
      "numeric - remove region:  R4_70\n",
      "numeric - remove region:  R4_71\n",
      "numeric - remove region:  R4_77\n",
      "R4_76\n",
      "R4_77.pkl aleady in data_folder\n",
      "R4_64-R4_77.pkl aleady in data_folder\n",
      "R4_63-R4_64-R4_65-R4_66-R4_67-R4_68-R4_77.pkl aleady in data_folder\n",
      "R4_77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pink/.conda/envs/dust/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove region:  R4_64\n",
      "remove region:  R4_64\n",
      "remove region:  R4_64\n",
      "remove region:  R4_64\n",
      "remove region:  R4_64\n",
      "numeric - remove region:  R4_64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pink/.conda/envs/dust/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove region:  R4_59\n",
      "remove region:  R4_60\n",
      "remove region:  R4_61\n",
      "remove region:  R4_62\n",
      "remove region:  R4_63\n",
      "remove region:  R4_64\n",
      "remove region:  R4_65\n",
      "remove region:  R4_59\n",
      "remove region:  R4_60\n",
      "remove region:  R4_61\n",
      "remove region:  R4_62\n",
      "remove region:  R4_63\n",
      "remove region:  R4_64\n",
      "remove region:  R4_65\n",
      "remove region:  R4_59\n",
      "remove region:  R4_60\n",
      "remove region:  R4_61\n",
      "remove region:  R4_62\n",
      "remove region:  R4_63\n",
      "remove region:  R4_64\n",
      "remove region:  R4_65\n",
      "remove region:  R4_59\n",
      "remove region:  R4_60\n",
      "remove region:  R4_61\n",
      "remove region:  R4_62\n",
      "remove region:  R4_63\n",
      "remove region:  R4_64\n",
      "remove region:  R4_65\n",
      "remove region:  R4_59\n",
      "remove region:  R4_60\n",
      "remove region:  R4_61\n",
      "remove region:  R4_62\n",
      "remove region:  R4_63\n",
      "remove region:  R4_64\n",
      "remove region:  R4_65\n",
      "numeric - remove region:  R4_59\n",
      "numeric - remove region:  R4_60\n",
      "numeric - remove region:  R4_61\n",
      "numeric - remove region:  R4_62\n",
      "numeric - remove region:  R4_63\n",
      "numeric - remove region:  R4_64\n",
      "numeric - remove region:  R4_65\n",
      "R4_59-R4_60-R4_61-R4_62-R4_63-R4_63-R4_64-R4_65-R4_65-R4_66-R4_67-R4_68.pkl aleady in data_folder\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [2], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[39mif\u001B[39;00m i \u001B[39m>\u001B[39m \u001B[39m0\u001B[39m:\n\u001B[1;32m      8\u001B[0m     line \u001B[39m=\u001B[39m \u001B[39mlist\u001B[39m(line)\n\u001B[0;32m----> 9\u001B[0m     region_num \u001B[39m=\u001B[39m line[\u001B[39m0\u001B[39;49m]\n\u001B[1;32m     10\u001B[0m     \u001B[39mprint\u001B[39m(line[\u001B[39m0\u001B[39m])\n\u001B[1;32m     11\u001B[0m     rm_groups \u001B[39m=\u001B[39m line[\u001B[39m1\u001B[39m]\u001B[39m.\u001B[39msplit(\u001B[39m'\u001B[39m\u001B[39m,\u001B[39m\u001B[39m'\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "file_list = os.listdir('data_folder')\n",
    "with open('data_folder/height_region_list.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, line in enumerate(reader):\n",
    "        \n",
    "        if i > 0:\n",
    "            line = list(line)\n",
    "            region_num = line[0]\n",
    "            print(line[0])\n",
    "            rm_groups = line[1].split(',')\n",
    "            rm_regions1 = line[2].split(',')\n",
    "            rm_regions2 = line[2].split(',')+line[3].split(',')\n",
    "            rm_regions3 = line[2].split(',')+line[3].split(',')+line[4].split(',')\n",
    "            rm_regions1.sort()\n",
    "            rm_regions2.sort()\n",
    "            rm_regions3.sort()\n",
    "            rm_regions1_pickle = \"-\".join(rm_regions1) + \".pkl\"\n",
    "            rm_regions2_pickle = \"-\".join(rm_regions2) + \".pkl\"\n",
    "            rm_regions3_pickle = \"-\".join(rm_regions3) + \".pkl\"\n",
    "            file_list = os.listdir('data_folder')\n",
    "            # print(file_list)\n",
    "            if rm_regions1_pickle not in file_list:\n",
    "                RMMakeNIERDataset(reset_db=False, save_processed_data=False, run_pca=True, start_date=20190101, until_date=20211231, test_date=20210101, remove_region=rm_regions1, preprocess_root='data_folder/')\n",
    "            else:\n",
    "                print(rm_regions1_pickle, \"aleady in data_folder\")\n",
    "            file_list = os.listdir('data_folder')\n",
    "            if rm_regions2_pickle not in file_list:\n",
    "                RMMakeNIERDataset(reset_db=False, save_processed_data=False, run_pca=True, start_date=20190101, until_date=20211231, test_date=20210101, remove_region=rm_regions2, preprocess_root='data_folder/')\n",
    "            else:\n",
    "                print(rm_regions2_pickle, \"aleady in data_folder\")\n",
    "            file_list = os.listdir('data_folder')\n",
    "            if rm_regions3_pickle not in file_list:\n",
    "                RMMakeNIERDataset(reset_db=False, save_processed_data=False, run_pca=True, start_date=20190101, until_date=20211231, test_date=20210101, remove_region=rm_regions3, preprocess_root='data_folder/')\n",
    "            else:\n",
    "                print(rm_regions3_pickle, \"aleady in data_folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R4_62\n",
      "['R4_77']\n",
      "R4_64\n",
      "['R4_77']\n",
      "R4_67\n",
      "['R4_77']\n",
      "R4_69\n",
      "['R4_77']\n",
      "R4_71\n",
      "['R4_77']\n",
      "R4_73\n",
      "['R4_77']\n",
      "R4_76\n",
      "['R4_77']\n",
      "R4_77\n",
      "['R4_63', 'R4_64']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('data_folder/height_region_list.csv', 'r', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, line in enumerate(reader):\n",
    "        if i > 0 and i < 9:\n",
    "            line = list(line)\n",
    "            region_num = line[0]\n",
    "            print(region_num)\n",
    "            rm_groups = line[1].split(',')\n",
    "            rm_regions1 = line[2].split(',')\n",
    "            rm_regions2 = line[2].split(',')+line[3].split(',')\n",
    "            rm_regions3 = line[2].split(',')+line[3].split(',')+line[4].split(',')\n",
    "            rm_regions1.sort()\n",
    "            rm_regions2.sort()\n",
    "            rm_regions3.sort()\n",
    "            print(rm_regions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9fca71497dee5836793b7ebf06d6d9f59e26b4c72fa15c96a9fb79daad4813a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
